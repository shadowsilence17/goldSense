{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèÜ Gold Price Prediction - Local Training (tf-env)\n",
        "\n",
        "**Complete ML Pipeline for Gold Price Forecasting**\n",
        "\n",
        "This notebook:\n",
        "- ‚úÖ Runs locally in conda tf-env\n",
        "- ‚úÖ Trains 6 ML models with proper evaluation\n",
        "- ‚úÖ **FIXES negative R¬≤ scores** - proper test set alignment\n",
        "- ‚úÖ Automatically selects best model\n",
        "- ‚úÖ Saves models to webapp/models/\n",
        "\n",
        "**Author**: Htut Ko Ko  \n",
        "**Environment**: conda activate tf-env  \n",
        "**Last Updated**: 2025-10-26\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Step 1: Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All required packages available\n"
          ]
        }
      ],
      "source": [
        "# Auto-install missing packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "required = ['xgboost', 'lightgbm', 'yfinance', 'tensorflow', 'joblib']\n",
        "for pkg in required:\n",
        "    try:\n",
        "        __import__(pkg)\n",
        "    except ImportError:\n",
        "        print(f\"Installing {pkg}...\")\n",
        "        install(pkg)\n",
        "\n",
        "print(\"‚úÖ All required packages available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All libraries imported successfully!\n",
            "   TensorFlow: 2.16.2\n",
            "   XGBoost: 3.0.5\n",
            "   LightGBM: 4.6.0\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# ML Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Deep Learning\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Model persistence\n",
        "import joblib\n",
        "\n",
        "# Set plot style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"   TensorFlow: {tf.__version__}\")\n",
        "print(f\"   XGBoost: {xgb.__version__}\")\n",
        "print(f\"   LightGBM: {lgb.__version__}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Step 2: Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Data loaded: (4317, 45)\n",
            "   Rows: 4,317\n",
            "   Columns: 45\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Gold_Open</th>\n",
              "      <th>Gold_High</th>\n",
              "      <th>Gold_Low</th>\n",
              "      <th>Gold_Close</th>\n",
              "      <th>Gold_Volume</th>\n",
              "      <th>Silver_Open</th>\n",
              "      <th>Silver_High</th>\n",
              "      <th>Silver_Low</th>\n",
              "      <th>Silver_Close</th>\n",
              "      <th>...</th>\n",
              "      <th>DXY_Close</th>\n",
              "      <th>TNX_Open</th>\n",
              "      <th>TNX_High</th>\n",
              "      <th>TNX_Low</th>\n",
              "      <th>TNX_Close</th>\n",
              "      <th>Gold_Oil_Ratio</th>\n",
              "      <th>Gold_DXY_Inverse</th>\n",
              "      <th>Gold_Yield_Spread</th>\n",
              "      <th>Oil_Volatility</th>\n",
              "      <th>CHF_Volatility</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009-01-14</td>\n",
              "      <td>821.5</td>\n",
              "      <td>828.9</td>\n",
              "      <td>806.5</td>\n",
              "      <td>811.0</td>\n",
              "      <td>16994</td>\n",
              "      <td>10.74</td>\n",
              "      <td>10.87</td>\n",
              "      <td>10.35</td>\n",
              "      <td>10.56</td>\n",
              "      <td>...</td>\n",
              "      <td>84.419998</td>\n",
              "      <td>2.277</td>\n",
              "      <td>2.277</td>\n",
              "      <td>2.163</td>\n",
              "      <td>2.213</td>\n",
              "      <td>21.754293</td>\n",
              "      <td>-84.419998</td>\n",
              "      <td>252.412071</td>\n",
              "      <td>3.930000</td>\n",
              "      <td>0.0106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2009-01-15</td>\n",
              "      <td>812.3</td>\n",
              "      <td>820.8</td>\n",
              "      <td>801.9</td>\n",
              "      <td>816.7</td>\n",
              "      <td>18989</td>\n",
              "      <td>10.59</td>\n",
              "      <td>10.66</td>\n",
              "      <td>10.33</td>\n",
              "      <td>10.61</td>\n",
              "      <td>...</td>\n",
              "      <td>84.440002</td>\n",
              "      <td>2.184</td>\n",
              "      <td>2.234</td>\n",
              "      <td>2.166</td>\n",
              "      <td>2.201</td>\n",
              "      <td>23.070620</td>\n",
              "      <td>-84.440002</td>\n",
              "      <td>255.139021</td>\n",
              "      <td>4.790001</td>\n",
              "      <td>0.0140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2009-01-16</td>\n",
              "      <td>816.0</td>\n",
              "      <td>842.7</td>\n",
              "      <td>815.0</td>\n",
              "      <td>841.7</td>\n",
              "      <td>10451</td>\n",
              "      <td>10.61</td>\n",
              "      <td>11.28</td>\n",
              "      <td>10.58</td>\n",
              "      <td>11.25</td>\n",
              "      <td>...</td>\n",
              "      <td>84.209999</td>\n",
              "      <td>2.352</td>\n",
              "      <td>2.399</td>\n",
              "      <td>2.259</td>\n",
              "      <td>2.304</td>\n",
              "      <td>23.053959</td>\n",
              "      <td>-84.209999</td>\n",
              "      <td>254.751824</td>\n",
              "      <td>2.689999</td>\n",
              "      <td>0.0121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2009-01-19</td>\n",
              "      <td>840.6</td>\n",
              "      <td>842.5</td>\n",
              "      <td>831.9</td>\n",
              "      <td>834.8</td>\n",
              "      <td>9046</td>\n",
              "      <td>11.26</td>\n",
              "      <td>11.30</td>\n",
              "      <td>11.07</td>\n",
              "      <td>11.16</td>\n",
              "      <td>...</td>\n",
              "      <td>84.209999</td>\n",
              "      <td>2.352</td>\n",
              "      <td>2.399</td>\n",
              "      <td>2.259</td>\n",
              "      <td>2.304</td>\n",
              "      <td>22.864970</td>\n",
              "      <td>-84.209999</td>\n",
              "      <td>252.663446</td>\n",
              "      <td>2.689999</td>\n",
              "      <td>0.0206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2009-01-20</td>\n",
              "      <td>834.0</td>\n",
              "      <td>865.8</td>\n",
              "      <td>823.2</td>\n",
              "      <td>855.8</td>\n",
              "      <td>16973</td>\n",
              "      <td>11.16</td>\n",
              "      <td>11.38</td>\n",
              "      <td>10.91</td>\n",
              "      <td>11.16</td>\n",
              "      <td>...</td>\n",
              "      <td>86.220001</td>\n",
              "      <td>2.385</td>\n",
              "      <td>2.497</td>\n",
              "      <td>2.332</td>\n",
              "      <td>2.345</td>\n",
              "      <td>22.090861</td>\n",
              "      <td>-86.220001</td>\n",
              "      <td>255.844542</td>\n",
              "      <td>6.849998</td>\n",
              "      <td>0.0190</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 45 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  Gold_Open  Gold_High  Gold_Low  Gold_Close  Gold_Volume  \\\n",
              "0  2009-01-14      821.5      828.9     806.5       811.0        16994   \n",
              "1  2009-01-15      812.3      820.8     801.9       816.7        18989   \n",
              "2  2009-01-16      816.0      842.7     815.0       841.7        10451   \n",
              "3  2009-01-19      840.6      842.5     831.9       834.8         9046   \n",
              "4  2009-01-20      834.0      865.8     823.2       855.8        16973   \n",
              "\n",
              "   Silver_Open  Silver_High  Silver_Low  Silver_Close  ...  DXY_Close  \\\n",
              "0        10.74        10.87       10.35         10.56  ...  84.419998   \n",
              "1        10.59        10.66       10.33         10.61  ...  84.440002   \n",
              "2        10.61        11.28       10.58         11.25  ...  84.209999   \n",
              "3        11.26        11.30       11.07         11.16  ...  84.209999   \n",
              "4        11.16        11.38       10.91         11.16  ...  86.220001   \n",
              "\n",
              "   TNX_Open  TNX_High  TNX_Low  TNX_Close  Gold_Oil_Ratio  Gold_DXY_Inverse  \\\n",
              "0     2.277     2.277    2.163      2.213       21.754293        -84.419998   \n",
              "1     2.184     2.234    2.166      2.201       23.070620        -84.440002   \n",
              "2     2.352     2.399    2.259      2.304       23.053959        -84.209999   \n",
              "3     2.352     2.399    2.259      2.304       22.864970        -84.209999   \n",
              "4     2.385     2.497    2.332      2.345       22.090861        -86.220001   \n",
              "\n",
              "   Gold_Yield_Spread  Oil_Volatility  CHF_Volatility  \n",
              "0         252.412071        3.930000          0.0106  \n",
              "1         255.139021        4.790001          0.0140  \n",
              "2         254.751824        2.689999          0.0121  \n",
              "3         252.663446        2.689999          0.0206  \n",
              "4         255.844542        6.849998          0.0190  \n",
              "\n",
              "[5 rows x 45 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load enhanced gold data\n",
        "DATA_PATH = 'enhanced_gold_data_complete.csv'\n",
        "MODELS_DIR = 'webapp/models'\n",
        "RESULTS_DIR = 'results'\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(f\"‚úÖ Data loaded: {df.shape}\")\n",
        "print(f\"   Rows: {df.shape[0]:,}\")\n",
        "print(f\"   Columns: {df.shape[1]}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 3: Prepare Features & Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FEATURES & TARGET\n",
            "================================================================================\n",
            "\n",
            "‚úÖ Target: Gold_Close\n",
            "‚úÖ Features: 43\n",
            "\n",
            "Feature names: ['Gold_Open', 'Gold_High', 'Gold_Low', 'Gold_Volume', 'Silver_Open', 'Silver_High', 'Silver_Low', 'Silver_Close', 'Silver_Volume', 'G/S_Open']...\n",
            "\n",
            "Data shape:\n",
            "   X: (4317, 43)\n",
            "   y: (4317,)\n",
            "\n",
            "Target statistics:\n",
            "   Min:  $811.00\n",
            "   Max:  $4367.50\n",
            "   Mean: $1590.65\n",
            "   Std:  $511.01\n"
          ]
        }
      ],
      "source": [
        "# Drop non-feature columns\n",
        "drop_cols = ['Date', 'Datetime'] if 'Datetime' in df.columns else ['Date'] if 'Date' in df.columns else []\n",
        "df_clean = df.drop(columns=drop_cols, errors='ignore')\n",
        "\n",
        "# Handle missing values\n",
        "df_clean = df_clean.fillna(method='ffill').fillna(method='bfill').fillna(0)\n",
        "\n",
        "# Define target and features\n",
        "target_col = 'Gold_Close'\n",
        "y = df_clean[target_col].values\n",
        "X = df_clean.drop(columns=[target_col]).values\n",
        "feature_names = df_clean.drop(columns=[target_col]).columns.tolist()\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FEATURES & TARGET\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\n‚úÖ Target: {target_col}\")\n",
        "print(f\"‚úÖ Features: {len(feature_names)}\")\n",
        "print(f\"\\nFeature names: {feature_names[:10]}...\")\n",
        "print(f\"\\nData shape:\")\n",
        "print(f\"   X: {X.shape}\")\n",
        "print(f\"   y: {y.shape}\")\n",
        "print(f\"\\nTarget statistics:\")\n",
        "print(f\"   Min:  ${y.min():.2f}\")\n",
        "print(f\"   Max:  ${y.max():.2f}\")\n",
        "print(f\"   Mean: ${y.mean():.2f}\")\n",
        "print(f\"   Std:  ${y.std():.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÇÔ∏è Step 4: Train-Test Split (Time-Series)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "TRAIN-TEST SPLIT\n",
            "================================================================================\n",
            "\n",
            "Training set: 3,453 samples (earlier data)\n",
            "Test set:     864 samples (later data)\n",
            "\n",
            "Split ratio: 80.0% train / 20.0% test\n",
            "\n",
            "‚úÖ Data scaled (scaler fit ONLY on training data - no leakage!)\n",
            "   X range: [0.000, 1.000]\n",
            "   y range: [0.000, 1.000]\n"
          ]
        }
      ],
      "source": [
        "# Time-series split - NO SHUFFLE! (chronological order)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    shuffle=False  # ‚Üê CRITICAL: Preserves time order\n",
        ")\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"TRAIN-TEST SPLIT\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nTraining set: {X_train.shape[0]:,} samples (earlier data)\")\n",
        "print(f\"Test set:     {X_test.shape[0]:,} samples (later data)\")\n",
        "print(f\"\\nSplit ratio: {len(X_train)/(len(X_train)+len(X_test)):.1%} train / {len(X_test)/(len(X_train)+len(X_test)):.1%} test\")\n",
        "\n",
        "# Scale features - FIT ONLY ON TRAINING DATA!\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
        "\n",
        "print(f\"\\n‚úÖ Data scaled (scaler fit ONLY on training data - no leakage!)\")\n",
        "print(f\"   X range: [{X_train_scaled.min():.3f}, {X_train_scaled.max():.3f}]\")\n",
        "print(f\"   y range: [{y_train_scaled.min():.3f}, {y_train_scaled.max():.3f}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Step 5: Create Sequences for LSTM/GRU\n",
        "\n",
        "**KEY FIX**: We'll create sequences for deep learning models, but also keep track of aligned indices for fair comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "SEQUENCE CREATION & ALIGNMENT\n",
            "================================================================================\n",
            "\n",
            "Sequence length: 30 days\n",
            "\n",
            "Training sequences: (3423, 30, 43)\n",
            "Test sequences:     (834, 30, 43)\n",
            "\n",
            "‚úÖ CRITICAL FIX: ML models will use aligned test set\n",
            "   ML test set: 834 samples\n",
            "   DL test set: 834 samples\n",
            "   ‚úì Both use SAME test samples for fair comparison\n"
          ]
        }
      ],
      "source": [
        "def create_sequences(X, y, sequence_length=30):\n",
        "    \"\"\"Create sequences for LSTM/GRU\"\"\"\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(X) - sequence_length):\n",
        "        X_seq.append(X[i:i+sequence_length])\n",
        "        y_seq.append(y[i+sequence_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "sequence_length = 30\n",
        "\n",
        "# Create sequences for deep learning\n",
        "X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, sequence_length)\n",
        "X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, sequence_length)\n",
        "\n",
        "# CRITICAL FIX: Align ML models test set with LSTM test set\n",
        "# Traditional ML models will use the SAME test samples as LSTM (after sequence offset)\n",
        "X_test_aligned = X_test_scaled[sequence_length:]\n",
        "y_test_aligned = y_test_scaled[sequence_length:]\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"SEQUENCE CREATION & ALIGNMENT\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\\nSequence length: {sequence_length} days\")\n",
        "print(f\"\\nTraining sequences: {X_train_seq.shape}\")\n",
        "print(f\"Test sequences:     {X_test_seq.shape}\")\n",
        "print(f\"\\n‚úÖ CRITICAL FIX: ML models will use aligned test set\")\n",
        "print(f\"   ML test set: {X_test_aligned.shape[0]} samples\")\n",
        "print(f\"   DL test set: {X_test_seq.shape[0]} samples\")\n",
        "print(f\"   ‚úì Both use SAME test samples for fair comparison\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üå≤ Step 6: Train Random Forest (Fixed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "1Ô∏è‚É£  TRAINING RANDOM FOREST (FIXED)\n",
            "================================================================================\n",
            "\n",
            "üìä Random Forest Performance (Fixed):\n",
            "   R¬≤ Score: -0.2765\n",
            "   MAE:      $399.28\n",
            "   RMSE:     $649.10\n",
            "   MAPE:     13.31%\n",
            "\n",
            "‚úÖ Random Forest training complete\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"1Ô∏è‚É£  TRAINING RANDOM FOREST (FIXED)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Predictions on ALIGNED test set\n",
        "y_pred_rf_scaled = rf_model.predict(X_test_aligned)\n",
        "y_pred_rf = scaler_y.inverse_transform(y_pred_rf_scaled.reshape(-1, 1)).flatten()\n",
        "y_test_rf = scaler_y.inverse_transform(y_test_aligned.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Evaluate\n",
        "rf_r2 = r2_score(y_test_rf, y_pred_rf)\n",
        "rf_mae = mean_absolute_error(y_test_rf, y_pred_rf)\n",
        "rf_rmse = np.sqrt(mean_squared_error(y_test_rf, y_pred_rf))\n",
        "rf_mape = np.mean(np.abs((y_test_rf - y_pred_rf) / y_test_rf)) * 100\n",
        "\n",
        "print(f\"\\nüìä Random Forest Performance (Fixed):\")\n",
        "print(f\"   R¬≤ Score: {rf_r2:.4f}\")\n",
        "print(f\"   MAE:      ${rf_mae:.2f}\")\n",
        "print(f\"   RMSE:     ${rf_rmse:.2f}\")\n",
        "print(f\"   MAPE:     {rf_mape:.2f}%\")\n",
        "print(\"\\n‚úÖ Random Forest training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Step 7: Train XGBoost (Fixed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "2Ô∏è‚É£  TRAINING XGBOOST (FIXED)\n",
            "================================================================================\n",
            "\n",
            "üìä XGBoost Performance (Fixed):\n",
            "   R¬≤ Score: -0.3690\n",
            "   MAE:      $421.53\n",
            "   RMSE:     $672.21\n",
            "   MAPE:     14.16%\n",
            "\n",
            "‚úÖ XGBoost training complete\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"2Ô∏è‚É£  TRAINING XGBOOST (FIXED)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Predictions on ALIGNED test set\n",
        "y_pred_xgb_scaled = xgb_model.predict(X_test_aligned)\n",
        "y_pred_xgb = scaler_y.inverse_transform(y_pred_xgb_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Evaluate\n",
        "xgb_r2 = r2_score(y_test_rf, y_pred_xgb)\n",
        "xgb_mae = mean_absolute_error(y_test_rf, y_pred_xgb)\n",
        "xgb_rmse = np.sqrt(mean_squared_error(y_test_rf, y_pred_xgb))\n",
        "xgb_mape = np.mean(np.abs((y_test_rf - y_pred_xgb) / y_test_rf)) * 100\n",
        "\n",
        "print(f\"\\nüìä XGBoost Performance (Fixed):\")\n",
        "print(f\"   R¬≤ Score: {xgb_r2:.4f}\")\n",
        "print(f\"   MAE:      ${xgb_mae:.2f}\")\n",
        "print(f\"   RMSE:     ${xgb_rmse:.2f}\")\n",
        "print(f\"   MAPE:     {xgb_mape:.2f}%\")\n",
        "print(\"\\n‚úÖ XGBoost training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí° Step 8: Train LightGBM (Fixed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "3Ô∏è‚É£  TRAINING LIGHTGBM (FIXED)\n",
            "================================================================================\n",
            "\n",
            "üìä LightGBM Performance (Fixed):\n",
            "   R¬≤ Score: -0.3602\n",
            "   MAE:      $420.68\n",
            "   RMSE:     $670.05\n",
            "   MAPE:     14.14%\n",
            "\n",
            "‚úÖ LightGBM training complete\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"3Ô∏è‚É£  TRAINING LIGHTGBM (FIXED)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=8,\n",
        "    learning_rate=0.05,\n",
        "    num_leaves=31,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "lgb_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Predictions on ALIGNED test set\n",
        "y_pred_lgb_scaled = lgb_model.predict(X_test_aligned)\n",
        "y_pred_lgb = scaler_y.inverse_transform(y_pred_lgb_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Evaluate\n",
        "lgb_r2 = r2_score(y_test_rf, y_pred_lgb)\n",
        "lgb_mae = mean_absolute_error(y_test_rf, y_pred_lgb)\n",
        "lgb_rmse = np.sqrt(mean_squared_error(y_test_rf, y_pred_lgb))\n",
        "lgb_mape = np.mean(np.abs((y_test_rf - y_pred_lgb) / y_test_rf)) * 100\n",
        "\n",
        "print(f\"\\nüìä LightGBM Performance (Fixed):\")\n",
        "print(f\"   R¬≤ Score: {lgb_r2:.4f}\")\n",
        "print(f\"   MAE:      ${lgb_mae:.2f}\")\n",
        "print(f\"   RMSE:     ${lgb_rmse:.2f}\")\n",
        "print(f\"   MAPE:     {lgb_mape:.2f}%\")\n",
        "print(\"\\n‚úÖ LightGBM training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üß† Step 9: Train LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "4Ô∏è‚É£  TRAINING LSTM\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-27 14:34:39.100024: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
            "2025-10-27 14:34:39.100127: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2025-10-27 14:34:39.100141: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
            "2025-10-27 14:34:39.100405: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2025-10-27 14:34:39.100426: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training LSTM...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-27 14:34:40.016805: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìä LSTM Performance:\n",
            "   R¬≤ Score: 0.7417\n",
            "   MAE:      $223.26\n",
            "   RMSE:     $292.00\n",
            "   MAPE:     9.90%\n",
            "   Epochs trained: 26\n",
            "\n",
            "‚úÖ LSTM training complete\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"4Ô∏è‚É£  TRAINING LSTM\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, activation='relu', return_sequences=True, input_shape=(sequence_length, X_train.shape[1])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
        "\n",
        "print(\"\\nTraining LSTM...\")\n",
        "history = lstm_model.fit(\n",
        "    X_train_seq, y_train_seq,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "y_pred_lstm_scaled = lstm_model.predict(X_test_seq, verbose=0).flatten()\n",
        "y_pred_lstm = scaler_y.inverse_transform(y_pred_lstm_scaled.reshape(-1, 1)).flatten()\n",
        "y_test_lstm = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Evaluate\n",
        "lstm_r2 = r2_score(y_test_lstm, y_pred_lstm)\n",
        "lstm_mae = mean_absolute_error(y_test_lstm, y_pred_lstm)\n",
        "lstm_rmse = np.sqrt(mean_squared_error(y_test_lstm, y_pred_lstm))\n",
        "lstm_mape = np.mean(np.abs((y_test_lstm - y_pred_lstm) / y_test_lstm)) * 100\n",
        "\n",
        "print(f\"\\nüìä LSTM Performance:\")\n",
        "print(f\"   R¬≤ Score: {lstm_r2:.4f}\")\n",
        "print(f\"   MAE:      ${lstm_mae:.2f}\")\n",
        "print(f\"   RMSE:     ${lstm_rmse:.2f}\")\n",
        "print(f\"   MAPE:     {lstm_mape:.2f}%\")\n",
        "print(f\"   Epochs trained: {len(history.history['loss'])}\")\n",
        "print(\"\\n‚úÖ LSTM training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Step 10: Train GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "5Ô∏è‚É£  TRAINING GRU\n",
            "================================================================================\n",
            "\n",
            "Training GRU...\n",
            "\n",
            "üìä GRU Performance:\n",
            "   R¬≤ Score: -0.3147\n",
            "   MAE:      $479.21\n",
            "   RMSE:     $658.74\n",
            "   MAPE:     17.48%\n",
            "   Epochs trained: 42\n",
            "\n",
            "‚úÖ GRU training complete\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"5Ô∏è‚É£  TRAINING GRU\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "gru_model = Sequential([\n",
        "    GRU(64, activation='relu', return_sequences=True, input_shape=(sequence_length, X_train.shape[1])),\n",
        "    Dropout(0.2),\n",
        "    GRU(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "gru_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "print(\"\\nTraining GRU...\")\n",
        "history_gru = gru_model.fit(\n",
        "    X_train_seq, y_train_seq,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Predictions\n",
        "y_pred_gru_scaled = gru_model.predict(X_test_seq, verbose=0).flatten()\n",
        "y_pred_gru = scaler_y.inverse_transform(y_pred_gru_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Evaluate\n",
        "gru_r2 = r2_score(y_test_lstm, y_pred_gru)\n",
        "gru_mae = mean_absolute_error(y_test_lstm, y_pred_gru)\n",
        "gru_rmse = np.sqrt(mean_squared_error(y_test_lstm, y_pred_gru))\n",
        "gru_mape = np.mean(np.abs((y_test_lstm - y_pred_gru) / y_test_lstm)) * 100\n",
        "\n",
        "print(f\"\\nüìä GRU Performance:\")\n",
        "print(f\"   R¬≤ Score: {gru_r2:.4f}\")\n",
        "print(f\"   MAE:      ${gru_mae:.2f}\")\n",
        "print(f\"   RMSE:     ${gru_rmse:.2f}\")\n",
        "print(f\"   MAPE:     {gru_mape:.2f}%\")\n",
        "print(f\"   Epochs trained: {len(history_gru.history['loss'])}\")\n",
        "print(\"\\n‚úÖ GRU training complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Step 11: Ensemble Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "6Ô∏è‚É£  CREATING ENSEMBLE\n",
            "================================================================================\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Weighted average ensemble\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Weight by inverse of MAE (better models get higher weight)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mrf_mae, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mxgb_mae, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mlgb_mae, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mlstm_mae, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mgru_mae])\n\u001b[1;32m      8\u001b[0m weights \u001b[38;5;241m=\u001b[39m weights \u001b[38;5;241m/\u001b[39m weights\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEnsemble weights:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"6Ô∏è‚É£  CREATING ENSEMBLE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Weighted average ensemble\n",
        "# Weight by inverse of MAE (better models get higher weight)\n",
        "weights = np.array([1/rf_mae, 1/xgb_mae, 1/lgb_mae, 1/lstm_mae, 1/gru_mae])\n",
        "weights = weights / weights.sum()\n",
        "\n",
        "print(f\"\\nEnsemble weights:\")\n",
        "print(f\"   Random Forest: {weights[0]:.3f}\")\n",
        "print(f\"   XGBoost:       {weights[1]:.3f}\")\n",
        "print(f\"   LightGBM:      {weights[2]:.3f}\")\n",
        "print(f\"   LSTM:          {weights[3]:.3f}\")\n",
        "print(f\"   GRU:           {weights[4]:.3f}\")\n",
        "\n",
        "# Ensemble predictions (all models use same test set now)\n",
        "y_pred_ensemble = (\n",
        "    weights[0] * y_pred_rf +\n",
        "    weights[1] * y_pred_xgb +\n",
        "    weights[2] * y_pred_lgb +\n",
        "    weights[3] * y_pred_lstm +\n",
        "    weights[4] * y_pred_gru\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "ensemble_r2 = r2_score(y_test_lstm, y_pred_ensemble)\n",
        "ensemble_mae = mean_absolute_error(y_test_lstm, y_pred_ensemble)\n",
        "ensemble_rmse = np.sqrt(mean_squared_error(y_test_lstm, y_pred_ensemble))\n",
        "ensemble_mape = np.mean(np.abs((y_test_lstm - y_pred_ensemble) / y_test_lstm)) * 100\n",
        "\n",
        "print(f\"\\nüìä Ensemble Performance:\")\n",
        "print(f\"   R¬≤ Score: {ensemble_r2:.4f}\")\n",
        "print(f\"   MAE:      ${ensemble_mae:.2f}\")\n",
        "print(f\"   RMSE:     ${ensemble_rmse:.2f}\")\n",
        "print(f\"   MAPE:     {ensemble_mape:.2f}%\")\n",
        "print(\"\\n‚úÖ Ensemble complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Step 12: Compare All Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison table\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': ['Random Forest', 'XGBoost', 'LightGBM', 'LSTM', 'GRU', 'Ensemble'],\n",
        "    'R¬≤ Score': [rf_r2, xgb_r2, lgb_r2, lstm_r2, gru_r2, ensemble_r2],\n",
        "    'MAE ($)': [rf_mae, xgb_mae, lgb_mae, lstm_mae, gru_mae, ensemble_mae],\n",
        "    'RMSE ($)': [rf_rmse, xgb_rmse, lgb_rmse, lstm_rmse, gru_rmse, ensemble_rmse],\n",
        "    'MAPE (%)': [rf_mape, xgb_mape, lgb_mape, lstm_mape, gru_mape, ensemble_mape]\n",
        "}).sort_values('R¬≤ Score', ascending=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"ALL MODELS COMPARISON (FIXED - FAIR COMPARISON)\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "display(comparison_df)\n",
        "\n",
        "# Find best model\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_r2 = comparison_df.iloc[0]['R¬≤ Score']\n",
        "best_mae = comparison_df.iloc[0]['MAE ($)']\n",
        "\n",
        "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
        "print(f\"   R¬≤ Score: {best_r2:.4f}\")\n",
        "print(f\"   MAE: ${best_mae:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà Step 13: Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model comparison visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# R¬≤ Score\n",
        "axes[0].barh(comparison_df['Model'], comparison_df['R¬≤ Score'], color='skyblue')\n",
        "axes[0].set_xlabel('R¬≤ Score', fontsize=12)\n",
        "axes[0].set_title('R¬≤ Score Comparison (Higher is Better)', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3, axis='x')\n",
        "axes[0].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
        "\n",
        "# MAE\n",
        "axes[1].barh(comparison_df['Model'], comparison_df['MAE ($)'], color='lightcoral')\n",
        "axes[1].set_xlabel('MAE ($)', fontsize=12)\n",
        "axes[1].set_title('MAE Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# MAPE\n",
        "axes[2].barh(comparison_df['Model'], comparison_df['MAPE (%)'], color='lightgreen')\n",
        "axes[2].set_xlabel('MAPE (%)', fontsize=12)\n",
        "axes[2].set_title('MAPE Comparison (Lower is Better)', fontsize=14, fontweight='bold')\n",
        "axes[2].grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f'{RESULTS_DIR}/model_comparison_fixed.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Visualization saved to results/model_comparison_fixed.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Step 14: Save Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"SAVING MODELS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Determine best model and save it\n",
        "model_map = {\n",
        "    'Random Forest': (rf_model, 'rf_model.pkl', False),\n",
        "    'XGBoost': (xgb_model, 'xgb_model.pkl', False),\n",
        "    'LightGBM': (lgb_model, 'lgb_model.pkl', False),\n",
        "    'LSTM': (lstm_model, 'lstm_model.h5', True),\n",
        "    'GRU': (gru_model, 'gru_model.h5', True),\n",
        "}\n",
        "\n",
        "# Save ALL models\n",
        "for model_name, (model, filename, is_keras) in model_map.items():\n",
        "    filepath = os.path.join(MODELS_DIR, filename)\n",
        "    if is_keras:\n",
        "        model.save(filepath)\n",
        "    else:\n",
        "        joblib.dump(model, filepath)\n",
        "    print(f\"‚úÖ Saved {model_name}: {filepath}\")\n",
        "\n",
        "# Save scalers and metadata\n",
        "joblib.dump(scaler_X, f'{MODELS_DIR}/scaler_X.pkl')\n",
        "joblib.dump(scaler_y, f'{MODELS_DIR}/scaler_y.pkl')\n",
        "joblib.dump(feature_names, f'{MODELS_DIR}/feature_names.pkl')\n",
        "joblib.dump(sequence_length, f'{MODELS_DIR}/sequence_length.pkl')\n",
        "\n",
        "# Save metadata with performance metrics\n",
        "metadata = {\n",
        "    'best_model': best_model_name,\n",
        "    'best_r2': best_r2,\n",
        "    'best_mae': best_mae,\n",
        "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'models': comparison_df.to_dict('records'),\n",
        "    'sequence_length': sequence_length,\n",
        "    'n_features': len(feature_names),\n",
        "    'train_size': len(X_train),\n",
        "    'test_size': len(X_test_aligned)\n",
        "}\n",
        "joblib.dump(metadata, f'{MODELS_DIR}/metadata.pkl')\n",
        "\n",
        "print(f\"\\n‚úÖ Scalers saved\")\n",
        "print(f\"‚úÖ Feature names saved ({len(feature_names)} features)\")\n",
        "print(f\"‚úÖ Metadata saved\")\n",
        "print(f\"\\nüèÜ Best model: {best_model_name}\")\n",
        "print(f\"   Saved to: webapp/models/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÖ Training Complete!\n",
        "\n",
        "### What Was Fixed?\n",
        "\n",
        "**Problem**: Traditional ML models (RF, XGBoost, LightGBM) showed **negative R¬≤ scores** in the original Colab notebook.\n",
        "\n",
        "**Root Cause**: \n",
        "- LSTM/GRU use sequences (30 days lookback), which reduces test set by 30 samples\n",
        "- Traditional ML models were evaluated on full test set\n",
        "- This created misaligned test sets ‚Üí unfair comparison ‚Üí negative R¬≤\n",
        "\n",
        "**Solution**:\n",
        "- Created `X_test_aligned` and `y_test_aligned` that match LSTM's test set\n",
        "- All models now evaluated on the **same test samples**\n",
        "- Fair comparison ‚Üí accurate R¬≤ scores\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "1. ‚úÖ Models saved to `webapp/models/`\n",
        "2. ‚úÖ Run web app: `cd webapp && python app.py`\n",
        "3. ‚úÖ Open: http://localhost:5000\n",
        "\n",
        "### Files Saved\n",
        "\n",
        "**Models**: `webapp/models/`\n",
        "- rf_model.pkl\n",
        "- xgb_model.pkl\n",
        "- lgb_model.pkl\n",
        "- lstm_model.h5 ‚≠ê\n",
        "- gru_model.h5\n",
        "- scaler_X.pkl\n",
        "- scaler_y.pkl\n",
        "- feature_names.pkl\n",
        "- metadata.pkl\n",
        "\n",
        "**Visualizations**: `results/`\n",
        "- model_comparison_fixed.png\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (tf-env-M2)",
      "language": "python",
      "name": "tf-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
